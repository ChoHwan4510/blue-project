import os
import torch
import clip
from PIL import Image
import shutil
import csv
from tqdm import tqdm
import argparse

# ëª…ë ¹ì¤„ ì¸ì ì²˜ë¦¬
parser = argparse.ArgumentParser(description="CLIP ê¸°ë°˜ ì´ë¯¸ì§€ í´ë” ë¶„ë¥˜ê¸°")
parser.add_argument("--image_dir", type=str, default="unsorted", help="ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œ")
parser.add_argument("--labels", type=str, default="labels.txt", help="CLIP ë¼ë²¨ íŒŒì¼")
parser.add_argument("--tags", type=str, default="tags.txt", help="í´ë”ëª… ë¦¬ìŠ¤íŠ¸ íŒŒì¼")
parser.add_argument("--output_dir", type=str, default="sorted", help="ë¶„ë¥˜ ê²°ê³¼ ì €ì¥ í´ë”")
parser.add_argument("--output_csv", type=str, default="result.csv", help="ê²°ê³¼ CSV íŒŒì¼ ê²½ë¡œ")
parser.add_argument("--threshold", type=float, default=0.3, help="ì‹ ë¢°ë„ ì„ê³„ê°’")
args = parser.parse_args()

# í™˜ê²½ ì„¤ì •
IMAGE_DIR = args.image_dir
LABEL_FILE = args.labels
TAG_FILE = args.tags
OUTPUT_DIR = args.output_dir
CSV_OUTPUT = args.output_csv
CONFIDENCE_THRESHOLD = args.threshold

device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

# í…ìŠ¤íŠ¸ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (ì£¼ì„, ë¹ˆ ì¤„ í•„í„°ë§)
def load_texts(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        return [
            line.strip()
            for line in f
            if line.strip() and not line.strip().startswith("#")
        ]

label_texts = load_texts(LABEL_FILE)
folder_tags = load_texts(TAG_FILE)

assert len(label_texts) == len(folder_tags), "âŒ labels.txtì™€ tags.txt ì¤„ ìˆ˜ê°€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤."

# ë¶„ë¥˜ ëŒ€ìƒ í´ë” ìƒì„±
for tag in folder_tags + ["unknown"]:
    os.makedirs(os.path.join(OUTPUT_DIR, tag), exist_ok=True)

# í…ìŠ¤íŠ¸ ì„ë² ë”©
with torch.no_grad():
    text_tokens = clip.tokenize(label_texts).to(device)
    text_features = model.encode_text(text_tokens)
    text_features /= text_features.norm(dim=-1, keepdim=True)

# ì´ë¯¸ì§€ ë¶„ë¥˜
results = []
image_files = [f for f in os.listdir(IMAGE_DIR) if f.lower().endswith((".jpg", ".jpeg", ".png"))]

for filename in tqdm(image_files, desc="ğŸ” ì´ë¯¸ì§€ ë¶„ë¥˜ ì¤‘"):
    try:
        image_path = os.path.join(IMAGE_DIR, filename)
        image = preprocess(Image.open(image_path).convert("RGB")).unsqueeze(0).to(device)

        with torch.no_grad():
            image_features = model.encode_image(image)
            image_features /= image_features.norm(dim=-1, keepdim=True)
            similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)
            confidence, index = similarity[0].max(0)

        conf_val = round(confidence.item(), 4)

        if conf_val >= CONFIDENCE_THRESHOLD:
            label = label_texts[index]
            tag = folder_tags[index]
        else:
            label = "unknown"
            tag = "unknown"

        shutil.copy(image_path, os.path.join(OUTPUT_DIR, tag, filename))

        results.append({
            "filename": filename,
            "predicted_label": label,
            "predicted_tag": tag,
            "confidence": conf_val
        })

    except Exception as e:
        print(f"âŒ {filename} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

# ------------------------------
# ê²°ê³¼ CSV ì €ì¥
# ------------------------------
with open(CSV_OUTPUT, "w", newline="", encoding="utf-8") as f:
    writer = csv.DictWriter(f, fieldnames=["filename", "predicted_label", "predicted_tag", "confidence"])
    writer.writeheader()
    writer.writerows(results)

print(f"\nâœ… ë¶„ë¥˜ ì™„ë£Œ: {len(results)}ê°œ ì´ë¯¸ì§€ â†’ {CSV_OUTPUT} ì €ì¥ë¨")

#python infer.py --image_dir "ë¶„ë¥˜í•  í´ë” ê²½ë¡œëª…" --output_dir "ë¶„ë¥˜ í›„ ì €ì¥í•  ê²½ë¡œëª…"